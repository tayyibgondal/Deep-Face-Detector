{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MS37DgBdGRL"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbXMK_63b0J7",
        "outputId": "46da8385-2903-406d-9bed-a00a356c7a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package libcudnn8 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "\u001b[1;31mE: \u001b[0mVersion '8.1.0.77-1+cuda11.2' for 'libcudnn8' was not found\u001b[0m\n",
            "Requirement already satisfied: protobuf~=3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install protobuf~=3.20.3\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yWcUVyTYb9_l"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT86iuVFdJsi"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R2WtD2LWcFtn"
      },
      "outputs": [],
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
        "                               with_info=True,\n",
        "                               as_supervised=True)\n",
        "\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1WBZPEvdTij",
        "outputId": "196c7dc3-e795-44c4-a996-d79c9adf5b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='ted_hrlr_translate',\n",
            "    full_name='ted_hrlr_translate/pt_to_en/1.0.0',\n",
            "    description=\"\"\"\n",
            "    Data sets derived from TED talk transcripts for comparing similar language pairs\n",
            "    where one is high resource and the other is low resource.\n",
            "    \"\"\",\n",
            "    config_description=\"\"\"\n",
            "    Translation dataset from pt to en in plain text.\n",
            "    \"\"\",\n",
            "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
            "    data_path='/root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=124.94 MiB,\n",
            "    dataset_size=10.89 MiB,\n",
            "    features=Translation({\n",
            "        'en': Text(shape=(), dtype=string),\n",
            "        'pt': Text(shape=(), dtype=string),\n",
            "    }),\n",
            "    supervised_keys=('pt', 'en'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=1803, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=51785, num_shards=1>,\n",
            "        'validation': <SplitInfo num_examples=1193, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
            "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
            "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
            "      booktitle = {HLT-NAACL},\n",
            "      year    = {2018},\n",
            "      }\"\"\",\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGENXLHhcIbs",
        "outputId": "85a80f75-dab8-44d2-d745-175d579eda77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
            "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_examples))\n",
        "print(type(val_examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XJOlWL6cQlN",
        "outputId": "6278403e-1b9e-4538-8503-b29aa0c33f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Examples in Portuguese:\n",
            "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
            "mas e se estes fatores fossem ativos ?\n",
            "mas eles não tinham a curiosidade de me testar .\n",
            "\n",
            "> Examples in English:\n",
            "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
            "but what if it were active ?\n",
            "but they did n't test for curiosity .\n"
          ]
        }
      ],
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in Portuguese:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pLO46WueLDt"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l-j2GKhocdCg",
        "outputId": "cbb10831-4072-4927-d46c-d28bafdc13c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./ted_hrlr_translate_pt_en_converter.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aUqMYBn-chLU"
      },
      "outputs": [],
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6xN0oVU7cki6"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS=128\n",
        "def prepare_batch(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
        "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en[:, :(MAX_TOKENS+1)]\n",
        "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
        "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
        "\n",
        "    return (pt, en_inputs), en_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kvGcr_DOeSB3"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "MAX_TOKENS=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NpWYr6RRenrK"
      },
      "outputs": [],
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XgrdDVxhepRu"
      },
      "outputs": [],
      "source": [
        "# Create training and validation set batches.\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcUNxQJBeq_V",
        "outputId": "037ebd63-fd84-40c5-9935-e739b4a17d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg_i7aXseuPX",
        "outputId": "c1e1ddfe-93bc-434d-9cac-01c541baded6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n"
          ]
        }
      ],
      "source": [
        "print(len(train_batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmeBgyoGewr8",
        "outputId": "3af6b254-60dc-4742-bc7c-663547e8dbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 106)\n",
            "(64, 105)\n",
            "(64, 105)\n"
          ]
        }
      ],
      "source": [
        "for (pt, en), en_labels in train_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ULjR45e_y3",
        "outputId": "2ddc9d57-58cb-45db-febf-0fe5ba0ffce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([   2   87 1631   15   15   15    0    0    0    0], shape=(10,), dtype=int64)\n",
            "tf.Tensor([  87 1631   15   15   15    3    0    0    0    0], shape=(10,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(en[0][:10])\n",
        "print(en_labels[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SSh1MQpe6e9"
      },
      "source": [
        "## Defining the components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYlawXw2H55m"
      },
      "source": [
        "### 1. Positional Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCXvgKAQed63",
        "outputId": "645e86d8-762a-4f23-e272-ee15e4e9c0f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "positional_encoding(4, 2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Efof73IIfjOw"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]  # No of words\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI917NVcjAwo",
        "outputId": "ff567d0b-c1e0-4372-b3ae-4776947f387e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 106, 512)\n",
            "(64, 105, 512)\n"
          ]
        }
      ],
      "source": [
        "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(), d_model=512)\n",
        "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n",
        "\n",
        "# pt and en are single sentences\n",
        "pt_emb = embed_pt(pt)\n",
        "en_emb = embed_en(en)\n",
        "print(pt_emb.shape)\n",
        "print(en_emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi7DlEsjkD8P",
        "outputId": "653e8c05-7205-4eb4-9155-cac32ebddfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 105)\n",
            "(64, 106)\n"
          ]
        }
      ],
      "source": [
        "mask_dec = tf.cast(en_emb._keras_mask, tf.float32) # for decoder\n",
        "mask_enc = tf.cast(pt_emb._keras_mask, tf.float32) # for encoder\n",
        "print(mask_dec.shape)\n",
        "print(mask_enc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVSMO45zIBea"
      },
      "source": [
        "### 2. Attention Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "wi51QCnhD_Im"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model  # e.g., 300\n",
        "        self.num_heads = num_heads  # e.g., 10\n",
        "\n",
        "        self.depth = d_model // self.num_heads  # e.g., 30\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.proj = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout)\n",
        "        ])\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Shape of x: (batch_size, n, d_model)\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch, heads, n, depth)\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v, mask, causal_mask, cross_attention=False):\n",
        "        # Shape of q, k, v: (batch, num_heads, n, depth)\n",
        "        # For cross attention: q is (batch, num_heads, n, 1, depth) and k, v are (batch, num_heads, 1, n_context, depth)\n",
        "        # For cross attention up: q is (batch, num_heads, n, depth) and k, v are (batch, num_heads, n_context, depth)\n",
        "        n = q.shape[2]\n",
        "        # n_context = k.shape[3]\n",
        "        n_context = k.shape[2]\n",
        "        batch_size = q.shape[0]\n",
        "        # print(f'n is: {n}')\n",
        "        # print(f'n context is: {n_context}')\n",
        "        # print(f'batch size is: {batch_size}')\n",
        "        # print(f'shape of q is: {q.shape} and of k is: {k.shape} and of v is: {v.shape}')\n",
        "\n",
        "        matmul_qk = tf.matmul(q, k, transpose_b=True)  # Shape: (batch, num_heads, n, d) * (batch, num_heads, d, n) --> (batch, num_heads, n, n)\n",
        "        # For cross attention: (batch, num_heads, n, 1, depth) * (batch, num_heads, 1, n_context, depth) --> (batch, num_heads, n, 1, n_context)\n",
        "        # For cross attention up: (batch, num_heads, n, depth) * (batch, num_heads, n_context, depth) --> (batch, num_heads, n, n_context)\n",
        "        # print(f'shape of qk is: {matmul_qk.shape}')\n",
        "\n",
        "        d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "        scaled_attention_logits = matmul_qk / tf.math.sqrt(d_k)  # Shape: (batch, num_heads, n, n)\n",
        "        # For cross attention, shape would be: (batch, num_heads, n, 1, n_context)\n",
        "        # For cross attention up, shape would be: (batch, num_heads, n, n_context)\n",
        "        # print(f'shape of mask is: {mask.shape}')\n",
        "        # print(f\"Cross attention is: {cross_attention}\")\n",
        "        # print(f'causal_mask is: {causal_mask}')\n",
        "\n",
        "        if mask is not None:\n",
        "            # Originally mask is of shape (batch, n), but here:\n",
        "            if cross_attention:\n",
        "              # Mask should be of shape: (batch, 1, n, 1, 1)\n",
        "              # Mask should be of shape up: (batch, 1, n, 1)\n",
        "              # reshaped_mask = tf.reshape(mask, (batch_size, 1, n, 1, 1))\n",
        "              reshaped_mask = tf.reshape(mask, (batch_size, 1, n, 1))\n",
        "              # print(f\"Reshaping mask according to cross att, shape: {reshaped_mask.shape}\")\n",
        "            else:\n",
        "              # Mask should be of shape: (batch, 1, 1, n)\n",
        "              reshaped_mask = tf.reshape(mask, (batch_size, 1, 1, n))\n",
        "              # print(f\"Reshaping mask according to normal att, shape: {reshaped_mask.shape}\")\n",
        "\n",
        "            scaled_attention_logits += reshaped_mask*-1e9  # Apply mask\n",
        "            # print(f'shape of attention logits after masking: {scaled_attention_logits.shape}')\n",
        "\n",
        "        # Shape of logits before causal mask: (batch, num_heads, n, n)\n",
        "        if causal_mask:\n",
        "            mask = tf.linalg.band_part(tf.ones((1, 1, n, n), dtype=tf.int32), num_lower=-1, num_upper=0)  # Shape: (1, 1, n, n)\n",
        "            mask = tf.where(mask==0, 1e-9, 1)\n",
        "            # print(f'causal mask shape is: {mask.shape}')\n",
        "            scaled_attention_logits = scaled_attention_logits * mask\n",
        "            # print(f'after applying causal mask, shape of attention logits: {scaled_attention_logits.shape}')\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # Shape: (batch, num_heads, n, n)\n",
        "        # print(f'attention weights shape is: {attention_weights.shape}')\n",
        "        # If cross_attention: (batch, num_heads, n, 1, n_context)\n",
        "        # If cross_attention up: (batch, num_heads, n, n_context)\n",
        "\n",
        "        output = tf.matmul(attention_weights, v)  # Shape: (batch, num_heads, n, depth)\n",
        "        # For cross attention: (batch, num_heads, n, 1, n_context) *  (batch, num_heads, 1, n_context, depth) --> (batch, num_heads, n, 1, depth)\n",
        "        # For cross attention up: (batch, num_heads, n, n_context) *  (batch, num_heads, n_context, depth) --> (batch, num_heads, n, depth)\n",
        "\n",
        "        # if cross_attention:\n",
        "        #   # print(f'Shape of output at the end of cross attention is: {output.shape}')\n",
        "        #   output = tf.squeeze(output, axis=3)\n",
        "\n",
        "        # print(f'shape of output is: {output.shape}')\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "    def call(self, query, key, value, mask, causal_mask, cross_attention=False):\n",
        "        # Shape of x: (batch_size, n, d_model)\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        q = self.wq(query)  # (batch_size, n, d_model)\n",
        "        k = self.wk(key)  # (batch_size, n_context, d_model)\n",
        "        v = self.wv(value)  # (batch_size, n_context, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size) # (batch, heads, n, depth)\n",
        "        k = self.split_heads(k, batch_size) # (batch, heads, n_context, depth)\n",
        "        v = self.split_heads(v, batch_size) # (batch, heads, n_context, depth)\n",
        "\n",
        "        # if cross_attention:\n",
        "        #   q = tf.expand_dims(q, axis=3)  # (batch, heads, n, 1, depth)\n",
        "        #   k = tf.expand_dims(k, axis=2)  # (batch, heads, 1, n_context, depth)\n",
        "        #   v = tf.expand_dims(v, axis=2)  # (batch, heads, 1, n_context, depth)\n",
        "\n",
        "\n",
        "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask, causal_mask, cross_attention) # (batch, num_heads, n, depth)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        concat_attention = self.proj(concat_attention)\n",
        "\n",
        "        return concat_attention, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6n0RA1zc2v2T"
      },
      "outputs": [],
      "source": [
        "# # Cross attention test\n",
        "# mha = MultiheadAttention(num_heads=16, d_model=64)\n",
        "\n",
        "# b = 32\n",
        "# d = 64\n",
        "# n = 10\n",
        "# n_context = 20\n",
        "\n",
        "# q = tf.ones((b, n, d))\n",
        "# k = tf.ones((b, n_context, d))\n",
        "# v = tf.ones((b, n_context, d))\n",
        "# mask = tf.ones((b, n), dtype=tf.float32)\n",
        "\n",
        "# print(q.shape)\n",
        "# print(k.shape)\n",
        "# print(v.shape)\n",
        "# print(mask.shape)\n",
        "# print(f'context: {n_context} and n: {n}')\n",
        "\n",
        "# mha(query=q, key=k, value=v, mask=mask, causal_mask=False, cross_attention=True)[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VTtWLkG-hssy"
      },
      "outputs": [],
      "source": [
        "# # Causal attention test\n",
        "# mha = MultiheadAttention(num_heads=2, d_model=200)\n",
        "# inp = tf.random.uniform((3, 5, 10))\n",
        "# mask = tf.zeros((3, 5))\n",
        "# mask = tf.reshape(mask, (3, 1, 1, 5))\n",
        "# output = mha(inp, inp, inp, mask, True)[0]\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uxzc62ATkGCn"
      },
      "outputs": [],
      "source": [
        "# All its child layers need num_heads and key_dim(or dmodel) for initialization\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = MultiheadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6-0y49Ugmjtq"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context, mask):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        mask=mask,\n",
        "        causal_mask=False,\n",
        "        cross_attention=True)\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlrK9CwHo_rk",
        "outputId": "2afa348a-89cd-4348-95c1-390108836ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: (64, 106, 512)\n",
            "input: (64, 105, 512)\n",
            "mask: (64, 105)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 105, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "sample_ca = CrossAttention(num_heads=2, d_model=512)\n",
        "\n",
        "print('context:', pt_emb.shape)\n",
        "print('input:', en_emb.shape)\n",
        "print('mask:', mask_dec.shape)\n",
        "\n",
        "sample_ca(en_emb, pt_emb, mask_dec).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qk35ucEkoOUc"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x, mask):\n",
        "    attn_output, attention_score = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        mask=mask,\n",
        "        causal_mask=False)\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k88l_-BMo0Gp",
        "outputId": "472d80ce-4c9c-4c57-fcd2-25abd7cf8477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 106, 512)\n",
            "(64, 106)\n",
            "(64, 106, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, d_model=512)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(mask_enc.shape)\n",
        "print(sample_gsa(pt_emb, mask_enc).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9_bbXMfapII4"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x, mask):\n",
        "    attn_output, attention_scores = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        mask=mask,\n",
        "        causal_mask=True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGOO3f7qqal6",
        "outputId": "c8dda6e2-c647-4671-b54b-0ef32a895134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 105, 512)\n",
            "(64, 105, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, d_model=512)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_csa(en_emb, mask_dec).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W01UGFnMsKi1"
      },
      "source": [
        "The output for early sequence elements doesn't depend on later elements, so it shouldn't matter if you trim elements before or after applying the layer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "43QzwZ8krhyy"
      },
      "outputs": [],
      "source": [
        "# out1 = sample_csa(embed_en(en[:, :3]))\n",
        "# out2 = sample_csa(embed_en(en))[:, :3]\n",
        "\n",
        "# tf.reduce_max(abs(out1 - out2)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHQCjj35IFI2"
      },
      "source": [
        "### 3. Feed Forward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dVliR8kWrqzS"
      },
      "outputs": [],
      "source": [
        "# This layer needs dmodel and dff for initialization\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(d_model*10, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld_KO0vxsexE",
        "outputId": "251b349e-f978-4c5a-bf24-d540a27bd834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 600)\n",
            "(10, 600)\n"
          ]
        }
      ],
      "source": [
        "sample_ffn = FeedForward(600)\n",
        "\n",
        "inp = tf.random.uniform((10, 600))  # n, d\n",
        "print(inp.shape)\n",
        "print(sample_ffn(inp).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSMsoixJILNJ"
      },
      "source": [
        "### 4. Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_F1Mk2sPtYQi"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        d_model=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model)\n",
        "\n",
        "  def call(self, x, mask):\n",
        "    x = self.self_attention(x, mask)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlqO6H6IzUgS",
        "outputId": "60614c71-5745-48d2-cf90-2b892678ce91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 106, 512)\n",
            "(64, 106, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_enc_layer = EncoderLayer(d_model=512, num_heads=2, dropout_rate=0.1)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_enc_layer(pt_emb, mask_enc).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SsHpEaNizi3T"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    mask = tf.cast(x._keras_mask, tf.float32)\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, mask)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnnmlY0z1y20",
        "outputId": "911d5739-3f11-421a-c000-21ca29311f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 106)\n",
            "(64, 106, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         vocab_size=8500)\n",
        "\n",
        "sample_encoder_output = sample_encoder(pt, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(pt.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvuyEw3BITy9"
      },
      "source": [
        "### 5. Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "K4RI8CZV19ai"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        d_model=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        d_model=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model)\n",
        "\n",
        "  def call(self, x, context, mask):\n",
        "    x = self.causal_self_attention(x=x, mask=mask)\n",
        "    x = self.cross_attention(x=x, context=context, mask=mask)\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuN0sv164RCU",
        "outputId": "35c6daf5-f9d3-4239-e712-22e1f7032ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 105, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=en_emb, context=pt_emb, mask=mask_dec\n",
        ")\n",
        "\n",
        "print(sample_decoder_layer_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ijHgsstU5BEE"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    mask = tf.cast(x._keras_mask, tf.float32)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context, mask)\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbIsZYOM5keN",
        "outputId": "7e3a862a-dfe3-4129-9fd9-18fedd69c0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 105)\n",
            "(64, 106, 512)\n",
            "(64, 105, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the decoder\n",
        "sample_decoder = Decoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         vocab_size=8000)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x=en,\n",
        "    context=pt_emb)\n",
        "\n",
        "# Print the shapes.\n",
        "print(en.shape)\n",
        "print(pt_emb.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E48_eqwIXVY"
      },
      "source": [
        "### 6. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1Iu4E0nj5mmT"
      },
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLOCQS898JGn"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NjBZxc1V8CLT"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cXAIcbPd8PUG"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
        "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWMUbh-68Ppj",
        "outputId": "59c5c4ab-aa41-46cf-df45-81d80bd4b0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 105)\n",
            "(64, 106)\n",
            "(64, 105, 7010)\n"
          ]
        }
      ],
      "source": [
        "output = transformer((pt, en))\n",
        "\n",
        "print(en.shape)\n",
        "print(pt.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leLmubcN8UIT"
      },
      "outputs": [],
      "source": [
        "# attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "# print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xw02z_f83pU",
        "outputId": "b4509a21-4f69-486e-a277-af207399e78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  2576512   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  2745088   \n",
            "                                                                 \n",
            " dense_158 (Dense)           multiple                  904290    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6225890 (23.75 MB)\n",
            "Trainable params: 6225890 (23.75 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cYJMUwxAhao"
      },
      "source": [
        "## Training Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKWK8CJrAisX"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCoF35lHCCNT"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "fvStOMj1CuG7",
        "outputId": "54fd8d52-e9b5-4b85-d832-cb5047deec93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCed00ECC7ul"
      },
      "source": [
        "## Set up loss metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrC1bimjCvnq"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none'\n",
        "  )\n",
        "  loss = loss_object(label, pred)\n",
        "  print()\n",
        "\n",
        "  mask = label!=0\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "\n",
        "  mask = label!=0\n",
        "  match = label==pred\n",
        "  match  = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2_kZ3qGHsRe"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQvIX3yD9VF",
        "outputId": "eab9f265-db09-48d8-8784-82af2e7c40a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0  Train Batch: 0/810\n",
            "\n",
            "Epoch: 0  Val Batch: 0/19\n"
          ]
        }
      ],
      "source": [
        "# Define the custom training loop\n",
        "file_path = \"results.txt\"\n",
        "n_epochs = 1\n",
        "train_size = len(train_batches)\n",
        "val_size = len(val_batches)\n",
        "cur_epoch = 0\n",
        "\n",
        "def custom_training_loop(model, train_batches, val_batches, epochs, optimizer, loss_fn):\n",
        "    global cur_epoch\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "\n",
        "        cur_train = 0\n",
        "        cur_val = 0\n",
        "\n",
        "        # Training\n",
        "        for batch, (input_data, target_data) in enumerate(train_batches.take(1)):\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(input_data, training=True)\n",
        "                loss = loss_fn(target_data, predictions)\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            accuracy = masked_accuracy(target_data, predictions)\n",
        "\n",
        "            total_loss += loss\n",
        "            total_accuracy += accuracy\n",
        "\n",
        "            print(f\"Epoch: {cur_epoch}  Train Batch: {cur_train}/{train_size}\")\n",
        "            cur_train += 1\n",
        "\n",
        "        average_loss = total_loss / (batch + 1)\n",
        "        average_accuracy = total_accuracy / (batch + 1)\n",
        "\n",
        "        # Open the file in append mode\n",
        "        with open(file_path, \"a\") as file:\n",
        "            string_to_append = f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\"\n",
        "            file.write(string_to_append)\n",
        "            file.write(\"\\n\")\n",
        "\n",
        "        # Validation\n",
        "        total_val_loss = 0\n",
        "        total_val_accuracy = 0\n",
        "        for batch, (input_data, target_data) in enumerate(val_batches.take(1)):\n",
        "            predictions = model(input_data, training=False)\n",
        "            loss = loss_fn(target_data, predictions)\n",
        "            accuracy = masked_accuracy(target_data, predictions)\n",
        "\n",
        "            total_val_loss += loss\n",
        "            total_val_accuracy += accuracy\n",
        "\n",
        "            print(f\"Epoch: {cur_epoch}  Val Batch: {cur_val}/{val_size}\")\n",
        "            cur_val += 1\n",
        "\n",
        "        average_val_loss = total_val_loss / (batch + 1)\n",
        "        average_val_accuracy = total_val_accuracy / (batch + 1)\n",
        "\n",
        "        with open(file_path, \"a\") as file:\n",
        "            string_to_append = f\"Validation Loss: {average_val_loss:.4f} - Validation Accuracy: {average_val_accuracy:.4f}\"\n",
        "            file.write(string_to_append)\n",
        "            file.write(\"\\n\\n\")\n",
        "\n",
        "        cur_epoch += 1\n",
        "\n",
        "# Call the custom training loop\n",
        "custom_training_loop(transformer, train_batches, val_batches, epochs=n_epochs, optimizer=optimizer, loss_fn=masked_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1-KUy54Hqhk"
      },
      "outputs": [],
      "source": [
        "# transformer.compile(\n",
        "#     loss=masked_loss,\n",
        "#     optimizer=optimizer,\n",
        "#     metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcowZMrkHuii"
      },
      "outputs": [],
      "source": [
        "# transformer.fit(train_batches,\n",
        "#                 epochs=20,\n",
        "#                 validation_data=val_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIpUXa3k4xRY"
      },
      "outputs": [],
      "source": [
        "# transformer.save('model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12JjTIVh4xRY"
      },
      "outputs": [],
      "source": [
        "# # Load the saved model\n",
        "# loaded_transformer = tf.keras.models.load_model('model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ_k6xrMb6P9"
      },
      "source": [
        "## Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY_uXsOhSmbb"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence  # (1, 11)\n",
        "\n",
        "    # As the output language is English, initialize the output with the\n",
        "    # English `[START]` token.\n",
        "    start_end = self.tokenizers.en.tokenize([''])[0]  # shape=(2,)\n",
        "    start = start_end[0][tf.newaxis]  # shape=(1,)\n",
        "    end = start_end[1][tf.newaxis]  # shape=(1,)\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())  # (1, X)\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "      # print(f\"Shape of prediction is: {predictions.shape}\")\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])  # Writing a tensor of shape 1\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    tokens = tokenizers.en.lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "\n",
        "    return text, tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeyQul6ZvxyI"
      },
      "outputs": [],
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J1Zrs10vjen"
      },
      "outputs": [],
      "source": [
        "translator = Translator(tokenizers, transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i-_RwV3m-hB"
      },
      "outputs": [],
      "source": [
        "sentence = 'este é um problema que temos que resolver.'\n",
        "ground_truth = 'this is a problem we have to solve .'\n",
        "\n",
        "translated_text, translated_tokens = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "E-4zpdHE91_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWuTkTIG4xRa"
      },
      "outputs": [],
      "source": [
        "cont = tf.ones((1, 11))\n",
        "enc = tf.ones((1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-UYPBTB4xRa",
        "outputId": "4e50d7d2-d487-4eea-9ba8-82c6d147e93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 11, 128)\n"
          ]
        }
      ],
      "source": [
        "context = transformer.encoder(cont)\n",
        "print(context.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = transformer.decoder(enc, context)"
      ],
      "metadata": {
        "id": "k5OEl1EC6BVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}