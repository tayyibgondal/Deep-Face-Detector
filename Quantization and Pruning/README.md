# Quantization and Pruning

This folder contains a project notebook on quantization and pruning of neural networks.

I'll provide code for mobile optimization techniques. These enable reduced model size and latency which makes it ideal for edge and IOT devices. I will start by training a Keras model then compare its model size and accuracy after going through these techniques:

- post-training quantization
- quantization aware training
- weight pruning
