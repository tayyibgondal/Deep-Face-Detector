{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67644f53147644a39ffbebfac5c4d14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6dd11ef36db4f9aad017a5f1830f36b",
              "IPY_MODEL_44f4f8c5d8b642a3a38054e93d483789",
              "IPY_MODEL_b3589a80d5204859b19d0d4ca0a1da18"
            ],
            "layout": "IPY_MODEL_d8cb10331837422fa37f5410bb2b113f"
          }
        },
        "c6dd11ef36db4f9aad017a5f1830f36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f7556aa0ba451cb86d111d73dc854b",
            "placeholder": "​",
            "style": "IPY_MODEL_9395dabdeb3d47279444915b93c52ec2",
            "value": "Map: 100%"
          }
        },
        "44f4f8c5d8b642a3a38054e93d483789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14450e710fc14500a1881b06ec82c222",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9b955d58cd245949c766048b79aa883",
            "value": 408
          }
        },
        "b3589a80d5204859b19d0d4ca0a1da18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77cdc2abf39742b69cb956c40761bba4",
            "placeholder": "​",
            "style": "IPY_MODEL_baccdd3ab6ce43bca74e80941459f6a7",
            "value": " 408/408 [00:00&lt;00:00, 875.89 examples/s]"
          }
        },
        "d8cb10331837422fa37f5410bb2b113f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f7556aa0ba451cb86d111d73dc854b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9395dabdeb3d47279444915b93c52ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14450e710fc14500a1881b06ec82c222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b955d58cd245949c766048b79aa883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77cdc2abf39742b69cb956c40761bba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baccdd3ab6ce43bca74e80941459f6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b095f8c1cb4938903b9cef1ce64fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_515b371780294b57ae786c8624f1090c",
              "IPY_MODEL_520509f65f9944848c9f70c200a1ae4b",
              "IPY_MODEL_0c4e695c12e9426a914399f6e92df8e6"
            ],
            "layout": "IPY_MODEL_7041989ba96949af9e20d9f83fbabb92"
          }
        },
        "515b371780294b57ae786c8624f1090c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d616bbe42048e3b1c13e61b47b5c23",
            "placeholder": "​",
            "style": "IPY_MODEL_91ac524af4074e238ee9ad86eb66d1c5",
            "value": "Map: 100%"
          }
        },
        "520509f65f9944848c9f70c200a1ae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111fb15c053e4ea792a31577647e2afe",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627e3ad7a30a46cb8dbfd5a5a5b9b840",
            "value": 1725
          }
        },
        "0c4e695c12e9426a914399f6e92df8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8138e67f09a440bf844824a2cd2a3eea",
            "placeholder": "​",
            "style": "IPY_MODEL_24adea452805409d8e179f5969058c7b",
            "value": " 1725/1725 [00:01&lt;00:00, 1713.22 examples/s]"
          }
        },
        "7041989ba96949af9e20d9f83fbabb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d616bbe42048e3b1c13e61b47b5c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ac524af4074e238ee9ad86eb66d1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111fb15c053e4ea792a31577647e2afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627e3ad7a30a46cb8dbfd5a5a5b9b840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8138e67f09a440bf844824a2cd2a3eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24adea452805409d8e179f5969058c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1182ec405fb840ad801b60a7066f7377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_483a70f0360e420597e074650285d68c",
              "IPY_MODEL_b0bf3af1d26e450aaf723a944d6d34fc",
              "IPY_MODEL_9320d63af12b40b191b6244e2d150ea6"
            ],
            "layout": "IPY_MODEL_890bf9fb5c664365be97a78ffd01bc35"
          }
        },
        "483a70f0360e420597e074650285d68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a9a40bb511451ba38d032daf388982",
            "placeholder": "​",
            "style": "IPY_MODEL_0769f321a73f4f4fa492ddd7ce0ab822",
            "value": "100%"
          }
        },
        "b0bf3af1d26e450aaf723a944d6d34fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2626834aea964b44ab57a9943729670b",
            "max": 1377,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c99907ab0564200ade8ad2e9353e668",
            "value": 1376
          }
        },
        "9320d63af12b40b191b6244e2d150ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9624c33b94534c978a214f91bc9b607c",
            "placeholder": "​",
            "style": "IPY_MODEL_c910de234a6d4e59b903fc6932683927",
            "value": " 1376/1377 [03:00&lt;00:00,  7.48it/s]"
          }
        },
        "890bf9fb5c664365be97a78ffd01bc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a9a40bb511451ba38d032daf388982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0769f321a73f4f4fa492ddd7ce0ab822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2626834aea964b44ab57a9943729670b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c99907ab0564200ade8ad2e9353e668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9624c33b94534c978a214f91bc9b607c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c910de234a6d4e59b903fc6932683927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68364737515941329c7f28636512f74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd562603c3674c55b0a08934a2190178",
              "IPY_MODEL_89523b71b2a140bf885dfafa4d19f010",
              "IPY_MODEL_dac5eb42427e46a4aa620598442e9091"
            ],
            "layout": "IPY_MODEL_31e993054f1c4d2f96c7f7b2ad89ed8e"
          }
        },
        "bd562603c3674c55b0a08934a2190178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00e4e3e07aaf4b8fbc8d8a73909eb546",
            "placeholder": "​",
            "style": "IPY_MODEL_dd6f43baa94747f59773090e5c5dc9f0",
            "value": "Downloading builder script: 100%"
          }
        },
        "89523b71b2a140bf885dfafa4d19f010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_012dc45dcbb54ab1a008a9e2c254ee85",
            "max": 5749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21d047b4a2f44f6db09fc03540eed542",
            "value": 5749
          }
        },
        "dac5eb42427e46a4aa620598442e9091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6cf48afd58a4574b5a6d3826cee8c66",
            "placeholder": "​",
            "style": "IPY_MODEL_8a24db217181481ebab63fb8b4f236dc",
            "value": " 5.75k/5.75k [00:00&lt;00:00, 358kB/s]"
          }
        },
        "31e993054f1c4d2f96c7f7b2ad89ed8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e4e3e07aaf4b8fbc8d8a73909eb546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6f43baa94747f59773090e5c5dc9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "012dc45dcbb54ab1a008a9e2c254ee85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d047b4a2f44f6db09fc03540eed542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6cf48afd58a4574b5a6d3826cee8c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a24db217181481ebab63fb8b4f236dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install accelerate\n",
        "# !pip install evaluate\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Nm4hs32Ppz6-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: The Pipeline"
      ],
      "metadata": {
        "id": "ZJYb1rZGZHF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# High level code\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "classifier([\"Oppenheimer is shit movie for sure!\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgcYWjaGZMep",
        "outputId": "f70da0dc-c2b0-41b3-e5b3-1c73c5c0f596"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9963310360908508}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Behind the Pipeline"
      ],
      "metadata": {
        "id": "muUBZj9-02Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Under the hood of pipeline"
      ],
      "metadata": {
        "id": "EheLAzal2k9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the particular tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "f3DkLBh6ZMVg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors='pt')\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy6hP-vjZMEq",
        "outputId": "54df3e1a-0ce4-473e-de81-f3bd00fb471c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading particular model\n",
        "from transformers import AutoModel  # Model without any head\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)\n"
      ],
      "metadata": {
        "id": "DF66D_aGa0bg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4WRIN2Cbb4w",
        "outputId": "e5a7257c-7b83-46d5-d94f-bf84205cdef0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "ffKWKR2ubw2Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO-XMa5Rb9Ei",
        "outputId": "e1eb9faa-2452-4a37-dc3a-3ba46844f66b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Post processing the model output\n",
        "import torch.nn.functional as F\n",
        "\n",
        "predictions = F.softmax(outputs.logits, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDcGCegLcGRy",
        "outputId": "b1ff09a0-8152-4f60-fdd3-396749d626e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config.id2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7MCngoyccLa",
        "outputId": "0e0c0fbf-a30a-4a14-964b-88caf188dd0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'NEGATIVE', 1: 'POSITIVE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Going in details of individual components: Model"
      ],
      "metadata": {
        "id": "MkPaucCqcoOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Instantiating model directly"
      ],
      "metadata": {
        "id": "Mzp9xZxOWtl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using automodel class"
      ],
      "metadata": {
        "id": "VsxlWSB3YY-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "PhVPSt_cSStM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "uY026O1oSMg0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using some specific class"
      ],
      "metadata": {
        "id": "DNnQgOHKYbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "ewbPLnFfXt-G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "RBqFoEWvX6XY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Instantiating Configuration for model and then the model\n"
      ],
      "metadata": {
        "id": "Y7x5mDonWywR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using autoconfig and giving it checkpoint or folder name"
      ],
      "metadata": {
        "id": "nnpcGlncW2S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig"
      ],
      "metadata": {
        "id": "_scPw8SjSGVx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_config = AutoConfig.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "4zlTAe9TScJ7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(bert_config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS7o0k37TnT0",
        "outputId": "689ebed8-be07-47a0-9f2d-06bafeb00069"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using bertconfig without any checkpoint name: returns random config file"
      ],
      "metadata": {
        "id": "74ZSOA3-XA0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig"
      ],
      "metadata": {
        "id": "iGF8ORrTWfnz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_config_random = BertConfig()"
      ],
      "metadata": {
        "id": "ervwg0IqWcOh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using bertconfig with the checkpoint name: returns non-random config file"
      ],
      "metadata": {
        "id": "CeQ2_4xKXK_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "TbNPw_Q8To8M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_config = BertConfig.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "q9QUq2hgTxOv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally instantiating the model using any of the above configuration files"
      ],
      "metadata": {
        "id": "_Bwt-zOvXRlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertModel(bert_config)"
      ],
      "metadata": {
        "id": "gWhEEytwT608"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Saving the model"
      ],
      "metadata": {
        "id": "z01POrjKYvM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.save_pretrained('/content/')"
      ],
      "metadata": {
        "id": "vD2PegtrU2AU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Going in details of individual components: Tokenizer"
      ],
      "metadata": {
        "id": "KukBn3q_cwk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "There are three types of tokenizers:\n",
        "1. Word based\n",
        "2. Character based\n",
        "3. Subword based\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "cYvjP4tHY2QS",
        "outputId": "4baa5657-f89d-4e35-f11d-d036fd8985a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThere are three types of tokenizers:\\n1. Word based\\n2. Character based\\n3. Subword based\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Word based tokenizers"
      ],
      "metadata": {
        "id": "4VS-O2kkdj96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Issues:\n",
        "  1. Similar words may not have similar tokens\n",
        "  2. Vocabulary size can become very large :( Large vocabularies result in heavy models\n",
        "  3. A lot of unknown words will occur\n",
        "\n",
        "To get word based tokens, create a unique vocabulary, assign each unique word\n",
        "an id to get a word-to-id dictionary, and then use this dictionary to assign tokens to the input text.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "siqCSQYidl5q",
        "outputId": "bf85fa28-cdcf-499f-b7fd-b3d70df1945d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIssues:\\n  1. Similar words may not have similar tokens\\n  2. Vocabulary size can become very large :( Large vocabularies result in heavy models\\n  3. A lot of unknown words will occur\\n\\nTo get word based tokens, create a unique vocabulary, assign each unique word\\nan id to get a word-to-id dictionary, and then use this dictionary to assign tokens to the input text.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Character Based Tokens"
      ],
      "metadata": {
        "id": "XPcmjcZ1fMMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        ". This has two primary benefits:\n",
        "    - The vocabulary is much smaller.\n",
        "    - There are much fewer out-of-vocabulary (unknown) tokens, since every word can be built from characters.\n",
        "\n",
        ". Problem:\n",
        "    - We’ll end up with a very large amount of tokens to be processed by our model.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "bviYMbndfQ7z",
        "outputId": "6f7d017e-7fe8-462e-b586-8f19a5fd9fd8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n. This has two primary benefits:\\n    - The vocabulary is much smaller.\\n    - There are much fewer out-of-vocabulary (unknown) tokens, since every word can be built from characters.\\n\\n. Problem:\\n    - We’ll end up with a very large amount of tokens to be processed by our model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Subword Tokenization\n",
        "\n"
      ],
      "metadata": {
        "id": "2CDObwrSgYQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- Do not split frequently occuring words\n",
        "- Otherwise split\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fyWp0zn6gdDF",
        "outputId": "bdc5a8cc-473f-45df-bc61-46e320fdb511"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n- Do not split frequently occuring words\\n- Otherwise split\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d) Code"
      ],
      "metadata": {
        "id": "UsGoDYOqh-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "'''\n",
        "Autotokenizer.from_pretrained takes in model checkpoint,\n",
        "and returns the algorithm(similar to config file) which the\n",
        "model used for tokenization during pretraining, and the\n",
        "vocabulary(similar to weights of the model)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "sFKAv-gpiCOF",
        "outputId": "c87224ea-1acb-46ff-ea55-d59406494a88"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAutotokenizer.from_pretrained takes in model checkpoint,\\nand returns the algorithm(similar to config file) which the\\nmodel used for tokenization during pretraining, and the\\nvocabulary(similar to weights of the model)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer('Yoo ma boi, how are you?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C0U5BIoiPXs",
        "outputId": "b00bb720-f929-4129-ea07-0f02db135b14"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 14941, 1186, 12477, 171, 8136, 117, 1293, 1132, 1128, 136, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "Phqu382zilkv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "ik61AZZKiuoU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"I love it when you call me Senorita...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqFl3L7Ki3Fp",
        "outputId": "ded1b0ea-cfa0-487c-eaec-8fe3cd7d0350"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 146, 1567, 1122, 1165, 1128, 1840, 1143, 14895, 9012, 1777, 119, 119, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e) Under the hood of tokenizer('string')"
      ],
      "metadata": {
        "id": "AqHZUxAGiktN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "wZd50BoKktQz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Binte Khan was Bin Hassan's first Love\""
      ],
      "metadata": {
        "id": "URj8YWwZk-qw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(input_text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuqN8Q4nlTNd",
        "outputId": "d136a963-2fcb-40ad-a69a-2a119245f53d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bin', '##te', 'Khan', 'was', 'Bin', 'Hassan', \"'\", 's', 'first', 'Love']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nQiW32glVvO",
        "outputId": "8a18bba4-61a4-4ef7-b9cb-00eaef90a15d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21700, 1566, 4340, 1108, 21700, 13583, 112, 188, 1148, 2185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_inputs = tokenizer.prepare_for_model(input_ids)\n",
        "print(final_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W30vKMPslii8",
        "outputId": "5a66f115-0356-45e8-8671-7fc33b2f05a4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 21700, 1566, 4340, 1108, 21700, 13583, 112, 188, 1148, 2185, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = tokenizer.decode(final_inputs['input_ids'])\n",
        "print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcFUyZp0l-DN",
        "outputId": "ed59af56-ef8b-4538-9654-5d7bb3e34402"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] Binte Khan was Bin Hassan's first Love [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f) Batching input sequences"
      ],
      "metadata": {
        "id": "ztrsxgvmnUtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "'''\n",
        "Following line will give error as the model expects\n",
        "not a single sentence, but a batch of sentences.\n",
        "'''\n",
        "# model(torch.tensor(final_inputs['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "f_jUSpzpmQhd",
        "outputId": "fee5fdfb-6568-4de0-baea-31ba84ad30bd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFollowing line will give error as the model expects\\nnot a single sentence, but a batch of sentences.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This line won't give any error\n",
        "model(torch.tensor([final_inputs['input_ids']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1OCSKlIu4ck",
        "outputId": "0ed4fee4-a618-4b4a-f398-f7928090ecc9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.4303, -2.0763]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apart from just getting the right tokens to input into\n",
        "# the model, we also need to pad tokens of all sentences\n",
        "# to equal length, and to get attention masks.\n",
        "\n",
        "# But keep in mind that pad token id should be the same\n",
        "# as the model used during training\n",
        "\n",
        "# All of this is done by tokenizer by default :)"
      ],
      "metadata": {
        "id": "M7o-sy5TvUHk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### g) More on tokenizer functionalities"
      ],
      "metadata": {
        "id": "YZ1tXEKCxLsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "model_inputs = tokenizer(sequences)"
      ],
      "metadata": {
        "id": "KBLdeuqQxoqw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Will pad the sequences up to the maximum sequence length\n",
        "model_inputs = tokenizer(sequences, padding=\"longest\")\n",
        "\n",
        "# Will pad the sequences up to the model max length\n",
        "# (512 for BERT or DistilBERT)\n",
        "model_inputs = tokenizer(sequences, padding=\"max_length\")\n",
        "\n",
        "# Will pad the sequences up to the specified max length\n",
        "model_inputs = tokenizer(sequences, padding=\"max_length\", max_length=8)"
      ],
      "metadata": {
        "id": "Z1V23CEuxPxE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "# Will truncate the sequences that are longer than the model max length\n",
        "# (512 for BERT or DistilBERT)\n",
        "model_inputs = tokenizer(sequences, truncation=True)\n",
        "\n",
        "# Will truncate the sequences that are longer than the specified max length\n",
        "model_inputs = tokenizer(sequences, max_length=8, truncation=True)"
      ],
      "metadata": {
        "id": "-h1rfhoKxY7g"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "# Returns PyTorch tensors\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Returns TensorFlow tensors\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"tf\")\n",
        "\n",
        "# Returns NumPy arrays\n",
        "model_inputs = tokenizer(sequences, padding=True, return_tensors=\"np\")"
      ],
      "metadata": {
        "id": "U-hSdj6txq8N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### h) Conclusion"
      ],
      "metadata": {
        "id": "wHdghhNeyKyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "output = model(**tokens)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNhcoCYExwUW",
        "outputId": "f092a2d0-d6d2-4dc8-91be-2beed607ca38"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
            "        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "oX82VfaJ0wEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Finetuning a pre-trained model"
      ],
      "metadata": {
        "id": "YtGffMes2p_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One step of model training, with two sentences as dataset"
      ],
      "metadata": {
        "id": "JYay-xZU6Rkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"This course is amazing!\",\n",
        "]\n",
        "batch = tokenizer(sequences, padding=True,\n",
        "                  truncation=True, return_tensors='pt')  # dictionary\n",
        "\n",
        "batch['labels'] = torch.tensor([1, 1])\n",
        "\n",
        "optimizer = AdamW(model.parameters())\n",
        "loss = model(**batch).loss\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78IHeb0yOq7",
        "outputId": "5de2ad01-4fc4-4621-f8dd-f485eb4440b8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Dataset library\n"
      ],
      "metadata": {
        "id": "3NlCs5m2Trj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "Ig3CMj9Z6E2N"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")"
      ],
      "metadata": {
        "id": "v_dgf-hx8El9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZtoByWm8S9V",
        "outputId": "dde76320-beaa-458d-9900-c1c1e3976a91"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "print(raw_train_dataset)\n",
        "print('---------------------')\n",
        "# Viewing a single example\n",
        "example = raw_train_dataset[0]\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCKmYpvh8bfH",
        "outputId": "06cb1d21-6305-4f9e-8729-0d93174e9774"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "    num_rows: 3668\n",
            "})\n",
            "---------------------\n",
            "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see which label represents what:\n",
        "raw_train_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBs4vOmJ8lDN",
        "outputId": "c7df19be-c5c2-4d92-c32c-ac0836414ca8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': Value(dtype='string', id=None),\n",
              " 'sentence2': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing all the elements of the dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-cased\"\n",
        "toeknizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Noice how we gave 2, and not 1 sentence as input to the tokenizer()\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"], padding=\"max_length\",\n",
        "      truncation=True, max_length=128\n",
        "  )\n",
        "\n",
        "tokenize_function(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_XYLE-d8pCl",
        "outputId": "4f0b5ba4-ad42-49ec-e387-01c6657e78f3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7277, 2180, 5303, 4806, 1117, 1711, 117, 2292, 1119, 1270, 107, 1103, 7737, 107, 117, 1104, 9938, 4267, 12223, 21811, 1117, 2554, 119, 102, 11336, 6732, 3384, 1106, 1140, 1112, 1178, 107, 1103, 7737, 107, 117, 7277, 2180, 5303, 4806, 1117, 1711, 1104, 9938, 4267, 12223, 21811, 1117, 2554, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasets.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l7jjxXq-6z8",
        "outputId": "3c59e95e-4e6c-44b9-d40b-229fa3957be7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'], 'validation': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'], 'test': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYR1bBfN_Qul",
        "outputId": "370779b2-9fc9-4d72-8567-2a10c42f22c5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivtuHjjG_mP6",
        "outputId": "85654eb2-1f6d-439c-b4c5-f47f77de5ffe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 3668\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulating the dataset according to what model is expecting.\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"idx\", \"sentence1\", \"sentence2\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "5ez86jHmADnj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKE76iXuADiS",
        "outputId": "9dcfd699-4d38-4cfa-b0fd-043249579c99"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other way to tokenize the dataset\n",
        "tokenized_dataset_v2 = tokenizer(\n",
        "    raw_datasets[\"train\"][\"sentence1\"],\n",
        "    raw_datasets[\"train\"][\"sentence2\"],\n",
        "    padding=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "eHoQhlLPPKHu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsgQ_RtCRpFX",
        "outputId": "250bdc4c-886f-4a76-eb23-97ba05e29584"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem with the second approach is that it returns a python dictionary and will work only if you have enough RAM. To keep the data as a dataset, we will use the Dataset.map() method."
      ],
      "metadata": {
        "id": "iZ4KjGGBR9sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Dataset Library (Putting together)"
      ],
      "metadata": {
        "id": "LQOIkk7WT0eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"], padding=\"max_length\",\n",
        "      truncation=True, max_length=128\n",
        "  )\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"idx\", \"sentence1\", \"sentence2\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets = tokenized_datasets.with_format('torch')\n",
        "print(tokenized_datasets[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "67644f53147644a39ffbebfac5c4d14b",
            "c6dd11ef36db4f9aad017a5f1830f36b",
            "44f4f8c5d8b642a3a38054e93d483789",
            "b3589a80d5204859b19d0d4ca0a1da18",
            "d8cb10331837422fa37f5410bb2b113f",
            "d5f7556aa0ba451cb86d111d73dc854b",
            "9395dabdeb3d47279444915b93c52ec2",
            "14450e710fc14500a1881b06ec82c222",
            "d9b955d58cd245949c766048b79aa883",
            "77cdc2abf39742b69cb956c40761bba4",
            "baccdd3ab6ce43bca74e80941459f6a7"
          ]
        },
        "id": "tXzAO0W9RsTG",
        "outputId": "68ee0a60-72b4-40d5-ef9e-a0c98916777a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67644f53147644a39ffbebfac5c4d14b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'labels': tensor(1), 'input_ids': tensor([  101,  7277,  2180,  5303,  4806,  1117,  1711,   117,  2292,  1119,\n",
            "         1270,   107,  1103,  7737,   107,   117,  1104,  9938,  4267, 12223,\n",
            "        21811,  1117,  2554,   119,   102, 11336,  6732,  3384,  1106,  1140,\n",
            "         1112,  1178,   107,  1103,  7737,   107,   117,  7277,  2180,  5303,\n",
            "         4806,  1117,  1711,  1104,  9938,  4267, 12223, 21811,  1117,  2554,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giving this dataset to torch dataloader"
      ],
      "metadata": {
        "id": "YRldxTGiXyaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"],\n",
        "                              batch_size=16,\n",
        "                              shuffle=True)\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  print(batch['input_ids'].shape)\n",
        "  if step > 5:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWF7JLP5WFUh",
        "outputId": "7c50cef8-ff76-4776-ee79-effb5e8b105c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doing above two sections by Dynamic Padding"
      ],
      "metadata": {
        "id": "ipDsdpeYZztl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"],\n",
        "      truncation=True, max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"idx\", \"sentence1\", \"sentence2\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets = tokenized_datasets.with_format('torch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f3b095f8c1cb4938903b9cef1ce64fb7",
            "515b371780294b57ae786c8624f1090c",
            "520509f65f9944848c9f70c200a1ae4b",
            "0c4e695c12e9426a914399f6e92df8e6",
            "7041989ba96949af9e20d9f83fbabb92",
            "66d616bbe42048e3b1c13e61b47b5c23",
            "91ac524af4074e238ee9ad86eb66d1c5",
            "111fb15c053e4ea792a31577647e2afe",
            "627e3ad7a30a46cb8dbfd5a5a5b9b840",
            "8138e67f09a440bf844824a2cd2a3eea",
            "24adea452805409d8e179f5969058c7b"
          ]
        },
        "id": "zbuhCQeFZIE2",
        "outputId": "03230410-8af8-4d0e-c124-731bc43067f9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3b095f8c1cb4938903b9cef1ce64fb7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"],\n",
        "                              batch_size=16,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=data_collator)\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  print(batch['input_ids'].shape)\n",
        "  if step > 5:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wEdVtxfaUtP",
        "outputId": "3d47c0b0-df08-46c1-e0d9-b71d79335489"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 80])\n",
            "torch.Size([16, 72])\n",
            "torch.Size([16, 87])\n",
            "torch.Size([16, 84])\n",
            "torch.Size([16, 77])\n",
            "torch.Size([16, 74])\n",
            "torch.Size([16, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer API"
      ],
      "metadata": {
        "id": "3lta7ldQq7pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"],\n",
        "      truncation=True, max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer)"
      ],
      "metadata": {
        "id": "37LymY69-BNU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments('test-trainer')"
      ],
      "metadata": {
        "id": "jEDliYXvdh0g"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvrNTZY-rEeZ",
        "outputId": "aa9c44ea-cde4-40c2-fe9a-8eb543c39a48"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "2hpE3REMzB5e"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train()"
      ],
      "metadata": {
        "id": "yoowxWaYzMq1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "# Trainer.predict returns named tuple containing 3 elements\n",
        "# predictions, labels, metric value\n",
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7WOdAohC0glW",
        "outputId": "95e84e56-1e3f-4170-d42b-fb8011de4d59"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(408, 2) (408,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbhI2TxA-_5M",
        "outputId": "a578ee1c-06a3-4413-b7bd-f0e774f27ee8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.6967151  -0.3756896 ]\n",
            " [-0.6876184  -0.391532  ]\n",
            " [-0.68211657 -0.37875637]\n",
            " [-0.6914974  -0.38169637]\n",
            " [-0.69527936 -0.38151777]\n",
            " [-0.70225835 -0.38775015]\n",
            " [-0.6917361  -0.40015525]\n",
            " [-0.6837981  -0.40252933]\n",
            " [-0.68638617 -0.37447944]\n",
            " [-0.69432944 -0.36988056]\n",
            " [-0.6873695  -0.382127  ]\n",
            " [-0.7064969  -0.39345717]\n",
            " [-0.67053777 -0.3508614 ]\n",
            " [-0.68649125 -0.37919453]\n",
            " [-0.692019   -0.38762498]\n",
            " [-0.6945637  -0.3777609 ]\n",
            " [-0.69388425 -0.39638898]\n",
            " [-0.6602345  -0.38809955]\n",
            " [-0.68243265 -0.38765866]\n",
            " [-0.66972566 -0.38133958]\n",
            " [-0.63704437 -0.42157665]\n",
            " [-0.678729   -0.38502657]\n",
            " [-0.68850255 -0.39314327]\n",
            " [-0.69666815 -0.39865604]\n",
            " [-0.6876614  -0.38122246]\n",
            " [-0.7025974  -0.39227557]\n",
            " [-0.672801   -0.40824246]\n",
            " [-0.68693805 -0.3873577 ]\n",
            " [-0.68496865 -0.39938754]\n",
            " [-0.68684095 -0.37949717]\n",
            " [-0.6943828  -0.38600424]\n",
            " [-0.6897569  -0.39814025]\n",
            " [-0.6925422  -0.3841939 ]\n",
            " [-0.6759791  -0.37521875]\n",
            " [-0.69334537 -0.37910366]\n",
            " [-0.67045295 -0.37173864]\n",
            " [-0.68579894 -0.38805583]\n",
            " [-0.6795278  -0.3823093 ]\n",
            " [-0.68414265 -0.39016894]\n",
            " [-0.68622553 -0.3885056 ]\n",
            " [-0.6835071  -0.4049312 ]\n",
            " [-0.68549335 -0.41208595]\n",
            " [-0.67593056 -0.39455926]\n",
            " [-0.68846065 -0.3889079 ]\n",
            " [-0.67151415 -0.36311537]\n",
            " [-0.6826975  -0.38343957]\n",
            " [-0.6926257  -0.38894755]\n",
            " [-0.6809627  -0.38587168]\n",
            " [-0.6878993  -0.39752236]\n",
            " [-0.6915553  -0.39198452]\n",
            " [-0.69300413 -0.3780275 ]\n",
            " [-0.6848232  -0.39636678]\n",
            " [-0.68891263 -0.4021916 ]\n",
            " [-0.68627787 -0.38181674]\n",
            " [-0.69077647 -0.3884358 ]\n",
            " [-0.689774   -0.38333687]\n",
            " [-0.6800222  -0.36285523]\n",
            " [-0.68567175 -0.40100983]\n",
            " [-0.68987894 -0.39628908]\n",
            " [-0.675415   -0.38487348]\n",
            " [-0.68416685 -0.38690352]\n",
            " [-0.69589    -0.37138835]\n",
            " [-0.67554665 -0.40208194]\n",
            " [-0.69258606 -0.3872744 ]\n",
            " [-0.69169456 -0.3902475 ]\n",
            " [-0.67645705 -0.38017598]\n",
            " [-0.680402   -0.3922304 ]\n",
            " [-0.6973493  -0.39213398]\n",
            " [-0.68823445 -0.41210032]\n",
            " [-0.69688785 -0.3772879 ]\n",
            " [-0.6945801  -0.38750374]\n",
            " [-0.67629826 -0.3826508 ]\n",
            " [-0.6731456  -0.38353527]\n",
            " [-0.6921764  -0.3934012 ]\n",
            " [-0.6900976  -0.39688432]\n",
            " [-0.6888081  -0.37359288]\n",
            " [-0.68532145 -0.38926297]\n",
            " [-0.68852955 -0.39763677]\n",
            " [-0.6939815  -0.38803914]\n",
            " [-0.6906823  -0.38481665]\n",
            " [-0.68513554 -0.37891743]\n",
            " [-0.695282   -0.38557315]\n",
            " [-0.68194187 -0.39068234]\n",
            " [-0.68414617 -0.3905905 ]\n",
            " [-0.70142615 -0.3989444 ]\n",
            " [-0.6988872  -0.38718426]\n",
            " [-0.6857055  -0.3964301 ]\n",
            " [-0.6482851  -0.42434892]\n",
            " [-0.69935846 -0.4044463 ]\n",
            " [-0.69035417 -0.38016862]\n",
            " [-0.68077904 -0.4015449 ]\n",
            " [-0.6940007  -0.39089826]\n",
            " [-0.6988817  -0.3775185 ]\n",
            " [-0.6798295  -0.38211083]\n",
            " [-0.6848454  -0.37996733]\n",
            " [-0.69335216 -0.39757723]\n",
            " [-0.68346554 -0.38987806]\n",
            " [-0.6776161  -0.3869285 ]\n",
            " [-0.6831659  -0.37119874]\n",
            " [-0.6959276  -0.4001252 ]\n",
            " [-0.6766876  -0.39497292]\n",
            " [-0.67593545 -0.39353362]\n",
            " [-0.68433934 -0.39477485]\n",
            " [-0.6875345  -0.39383435]\n",
            " [-0.69142574 -0.39915988]\n",
            " [-0.68990636 -0.3856276 ]\n",
            " [-0.68886256 -0.38937148]\n",
            " [-0.6502728  -0.41356108]\n",
            " [-0.6433585  -0.39307642]\n",
            " [-0.69539535 -0.37563044]\n",
            " [-0.6928528  -0.37279838]\n",
            " [-0.6899427  -0.3917301 ]\n",
            " [-0.6883136  -0.38170853]\n",
            " [-0.69263065 -0.3814775 ]\n",
            " [-0.6869012  -0.3848662 ]\n",
            " [-0.68851286 -0.39289582]\n",
            " [-0.6910304  -0.39341012]\n",
            " [-0.6864559  -0.38705832]\n",
            " [-0.6801601  -0.3795945 ]\n",
            " [-0.6954499  -0.38695318]\n",
            " [-0.68517673 -0.3832693 ]\n",
            " [-0.7024151  -0.39739126]\n",
            " [-0.6767137  -0.40300372]\n",
            " [-0.6815364  -0.38522393]\n",
            " [-0.6916095  -0.40067914]\n",
            " [-0.685376   -0.3948178 ]\n",
            " [-0.67576295 -0.3954067 ]\n",
            " [-0.68040484 -0.40086645]\n",
            " [-0.6867896  -0.388677  ]\n",
            " [-0.69331264 -0.39020076]\n",
            " [-0.6796597  -0.38324925]\n",
            " [-0.6852878  -0.3928454 ]\n",
            " [-0.6848326  -0.38350466]\n",
            " [-0.6913228  -0.39992988]\n",
            " [-0.68493134 -0.38906303]\n",
            " [-0.68597966 -0.3865887 ]\n",
            " [-0.6756184  -0.39255792]\n",
            " [-0.6809609  -0.37385416]\n",
            " [-0.6917163  -0.38747686]\n",
            " [-0.67936146 -0.39246765]\n",
            " [-0.6880256  -0.38591307]\n",
            " [-0.6926887  -0.37895885]\n",
            " [-0.6521536  -0.39389336]\n",
            " [-0.700886   -0.38028297]\n",
            " [-0.6977865  -0.38779277]\n",
            " [-0.68836033 -0.38548866]\n",
            " [-0.682704   -0.3914324 ]\n",
            " [-0.68885756 -0.38768986]\n",
            " [-0.68047166 -0.39743844]\n",
            " [-0.6809189  -0.38479754]\n",
            " [-0.6793375  -0.38538754]\n",
            " [-0.6874311  -0.40595904]\n",
            " [-0.6891659  -0.39577648]\n",
            " [-0.69598955 -0.37486547]\n",
            " [-0.68529433 -0.39118874]\n",
            " [-0.6935247  -0.38388118]\n",
            " [-0.6932717  -0.39553562]\n",
            " [-0.67622    -0.39545572]\n",
            " [-0.6927031  -0.39430922]\n",
            " [-0.688697   -0.39301336]\n",
            " [-0.6824621  -0.40150642]\n",
            " [-0.6880256  -0.39206585]\n",
            " [-0.6915461  -0.3864181 ]\n",
            " [-0.6921768  -0.38892874]\n",
            " [-0.68215024 -0.38057423]\n",
            " [-0.6935968  -0.3866075 ]\n",
            " [-0.693908   -0.37639445]\n",
            " [-0.6842607  -0.4031803 ]\n",
            " [-0.6867112  -0.3986389 ]\n",
            " [-0.6739947  -0.39341733]\n",
            " [-0.68329674 -0.3927983 ]\n",
            " [-0.69662887 -0.38038847]\n",
            " [-0.6944563  -0.39506295]\n",
            " [-0.6884052  -0.3770004 ]\n",
            " [-0.6813627  -0.38443118]\n",
            " [-0.6827996  -0.3912865 ]\n",
            " [-0.6817931  -0.39002934]\n",
            " [-0.6697653  -0.3936387 ]\n",
            " [-0.6975279  -0.38676435]\n",
            " [-0.688544   -0.39393872]\n",
            " [-0.68503606 -0.3899767 ]\n",
            " [-0.67178684 -0.38115722]\n",
            " [-0.6880853  -0.387427  ]\n",
            " [-0.688916   -0.38826534]\n",
            " [-0.68580294 -0.38611618]\n",
            " [-0.6877025  -0.3799031 ]\n",
            " [-0.67508465 -0.39418224]\n",
            " [-0.6927126  -0.3962564 ]\n",
            " [-0.6919144  -0.39095157]\n",
            " [-0.6865387  -0.39790034]\n",
            " [-0.6889549  -0.3930543 ]\n",
            " [-0.68233806 -0.38941363]\n",
            " [-0.68418616 -0.38506746]\n",
            " [-0.68754303 -0.3811385 ]\n",
            " [-0.6888791  -0.40111336]\n",
            " [-0.66196287 -0.38766605]\n",
            " [-0.6875589  -0.38150454]\n",
            " [-0.6929465  -0.38373792]\n",
            " [-0.6827042  -0.38079685]\n",
            " [-0.68831164 -0.38755238]\n",
            " [-0.68069834 -0.38627082]\n",
            " [-0.6945878  -0.37516603]\n",
            " [-0.67952955 -0.3714957 ]\n",
            " [-0.6860381  -0.38500968]\n",
            " [-0.6865357  -0.38002113]\n",
            " [-0.6814059  -0.37727088]\n",
            " [-0.70453143 -0.3851531 ]\n",
            " [-0.69746304 -0.39324826]\n",
            " [-0.6873894  -0.37673354]\n",
            " [-0.6917529  -0.37712526]\n",
            " [-0.6838269  -0.37490514]\n",
            " [-0.6885205  -0.39277938]\n",
            " [-0.66278094 -0.39411992]\n",
            " [-0.69058466 -0.3897836 ]\n",
            " [-0.6847564  -0.39071396]\n",
            " [-0.69102395 -0.38428813]\n",
            " [-0.6887713  -0.3873247 ]\n",
            " [-0.68302584 -0.39224356]\n",
            " [-0.68588054 -0.3670675 ]\n",
            " [-0.67663896 -0.37951568]\n",
            " [-0.69516975 -0.39046916]\n",
            " [-0.6980859  -0.39879853]\n",
            " [-0.6851857  -0.39539883]\n",
            " [-0.6717273  -0.37323287]\n",
            " [-0.6962493  -0.3789847 ]\n",
            " [-0.69554806 -0.3859606 ]\n",
            " [-0.69132864 -0.38975838]\n",
            " [-0.69639003 -0.38245535]\n",
            " [-0.69244266 -0.40083826]\n",
            " [-0.6839285  -0.3904547 ]\n",
            " [-0.69078904 -0.38171104]\n",
            " [-0.6719523  -0.3709961 ]\n",
            " [-0.68319345 -0.40908575]\n",
            " [-0.6862673  -0.37626907]\n",
            " [-0.6825909  -0.37491733]\n",
            " [-0.68762547 -0.38798827]\n",
            " [-0.69802684 -0.3873848 ]\n",
            " [-0.6695903  -0.38482964]\n",
            " [-0.68682253 -0.39536813]\n",
            " [-0.6952592  -0.3807478 ]\n",
            " [-0.6879269  -0.38250044]\n",
            " [-0.69544566 -0.37175623]\n",
            " [-0.70089126 -0.38646746]\n",
            " [-0.6975508  -0.3852129 ]\n",
            " [-0.69894147 -0.38310286]\n",
            " [-0.7025908  -0.38327292]\n",
            " [-0.67062026 -0.39032272]\n",
            " [-0.6765447  -0.40728268]\n",
            " [-0.69463426 -0.3902158 ]\n",
            " [-0.6863874  -0.38960782]\n",
            " [-0.68577194 -0.37966374]\n",
            " [-0.6865648  -0.38813758]\n",
            " [-0.6871656  -0.38344938]\n",
            " [-0.6789528  -0.37575084]\n",
            " [-0.6889728  -0.36524826]\n",
            " [-0.68852425 -0.397483  ]\n",
            " [-0.69338095 -0.39637765]\n",
            " [-0.6817959  -0.3814676 ]\n",
            " [-0.69018435 -0.3825609 ]\n",
            " [-0.6773074  -0.4036446 ]\n",
            " [-0.6886721  -0.3831454 ]\n",
            " [-0.687996   -0.3768317 ]\n",
            " [-0.68915796 -0.37428477]\n",
            " [-0.68677807 -0.39639315]\n",
            " [-0.6938037  -0.39910927]\n",
            " [-0.6854102  -0.38990912]\n",
            " [-0.6801119  -0.38415053]\n",
            " [-0.68787116 -0.38456166]\n",
            " [-0.69522864 -0.3880583 ]\n",
            " [-0.69277704 -0.39669204]\n",
            " [-0.68226737 -0.39382845]\n",
            " [-0.6774189  -0.39325395]\n",
            " [-0.6914835  -0.37638074]\n",
            " [-0.7051517  -0.39181718]\n",
            " [-0.6882231  -0.37865576]\n",
            " [-0.68028545 -0.38017595]\n",
            " [-0.697621   -0.387307  ]\n",
            " [-0.67783064 -0.3888708 ]\n",
            " [-0.6862582  -0.37844327]\n",
            " [-0.6765363  -0.38465258]\n",
            " [-0.69471586 -0.38040942]\n",
            " [-0.66401654 -0.395936  ]\n",
            " [-0.6907114  -0.38302198]\n",
            " [-0.6873185  -0.36461607]\n",
            " [-0.69403374 -0.3953056 ]\n",
            " [-0.700516   -0.38767624]\n",
            " [-0.69412935 -0.389763  ]\n",
            " [-0.69027114 -0.3822381 ]\n",
            " [-0.6937389  -0.3917419 ]\n",
            " [-0.68398887 -0.3851655 ]\n",
            " [-0.6792026  -0.39392623]\n",
            " [-0.6917371  -0.38982058]\n",
            " [-0.6932932  -0.38439327]\n",
            " [-0.6819415  -0.40152588]\n",
            " [-0.6802097  -0.3886686 ]\n",
            " [-0.6921259  -0.3877832 ]\n",
            " [-0.6990481  -0.39729357]\n",
            " [-0.69635797 -0.38665903]\n",
            " [-0.68549776 -0.40535915]\n",
            " [-0.67867905 -0.4013777 ]\n",
            " [-0.69359994 -0.3850459 ]\n",
            " [-0.68877244 -0.39191428]\n",
            " [-0.6821099  -0.37349677]\n",
            " [-0.6814465  -0.38923553]\n",
            " [-0.68809354 -0.41124338]\n",
            " [-0.6830782  -0.3733138 ]\n",
            " [-0.6929657  -0.40695557]\n",
            " [-0.6861195  -0.39078027]\n",
            " [-0.66821563 -0.3946702 ]\n",
            " [-0.68281907 -0.38300252]\n",
            " [-0.6929567  -0.39757836]\n",
            " [-0.69584477 -0.38210118]\n",
            " [-0.662457   -0.40084922]\n",
            " [-0.6787425  -0.37839714]\n",
            " [-0.68107074 -0.38320827]\n",
            " [-0.6868622  -0.39216113]\n",
            " [-0.670728   -0.3862853 ]\n",
            " [-0.69127893 -0.38471034]\n",
            " [-0.6904999  -0.38767   ]\n",
            " [-0.68957484 -0.38912103]\n",
            " [-0.6801071  -0.3802769 ]\n",
            " [-0.68922204 -0.38652512]\n",
            " [-0.6455123  -0.3472448 ]\n",
            " [-0.6726028  -0.39239746]\n",
            " [-0.69170606 -0.3919024 ]\n",
            " [-0.6950413  -0.38823244]\n",
            " [-0.6828973  -0.37206778]\n",
            " [-0.68518674 -0.37730682]\n",
            " [-0.6876471  -0.3884341 ]\n",
            " [-0.6922167  -0.38281047]\n",
            " [-0.6948116  -0.38440573]\n",
            " [-0.6885105  -0.39085832]\n",
            " [-0.6952167  -0.38765922]\n",
            " [-0.69788295 -0.3759353 ]\n",
            " [-0.6889516  -0.38030258]\n",
            " [-0.6893558  -0.4029901 ]\n",
            " [-0.67674613 -0.393764  ]\n",
            " [-0.6833913  -0.3872491 ]\n",
            " [-0.6906409  -0.37837994]\n",
            " [-0.70341945 -0.3863975 ]\n",
            " [-0.69780236 -0.3855137 ]\n",
            " [-0.68236256 -0.3905993 ]\n",
            " [-0.67225534 -0.3909406 ]\n",
            " [-0.6804033  -0.3700164 ]\n",
            " [-0.67821306 -0.39021558]\n",
            " [-0.6963295  -0.3877081 ]\n",
            " [-0.6935298  -0.39528695]\n",
            " [-0.69573957 -0.39157405]\n",
            " [-0.6997545  -0.40577418]\n",
            " [-0.6822797  -0.3987166 ]\n",
            " [-0.69315225 -0.38132122]\n",
            " [-0.6887888  -0.39823818]\n",
            " [-0.68399936 -0.3792648 ]\n",
            " [-0.6842171  -0.38429046]\n",
            " [-0.6882031  -0.37872547]\n",
            " [-0.6726904  -0.38791633]\n",
            " [-0.67756087 -0.39706814]\n",
            " [-0.6784125  -0.3821443 ]\n",
            " [-0.6867161  -0.3950941 ]\n",
            " [-0.6904707  -0.37961712]\n",
            " [-0.6888819  -0.3832041 ]\n",
            " [-0.6952811  -0.38964933]\n",
            " [-0.69126445 -0.39239848]\n",
            " [-0.697307   -0.38609475]\n",
            " [-0.6879708  -0.38820297]\n",
            " [-0.6937733  -0.40317434]\n",
            " [-0.6942548  -0.38194725]\n",
            " [-0.687582   -0.38550335]\n",
            " [-0.6787101  -0.37939048]\n",
            " [-0.68406165 -0.38492885]\n",
            " [-0.6868702  -0.38633248]\n",
            " [-0.69061786 -0.3778063 ]\n",
            " [-0.69349754 -0.38973913]\n",
            " [-0.69838905 -0.38453904]\n",
            " [-0.6846735  -0.39674285]\n",
            " [-0.6752026  -0.38655737]\n",
            " [-0.684741   -0.38068378]\n",
            " [-0.6870081  -0.3873479 ]\n",
            " [-0.68677163 -0.38626993]\n",
            " [-0.6913841  -0.39816454]\n",
            " [-0.6809881  -0.40389055]\n",
            " [-0.68303734 -0.3899424 ]\n",
            " [-0.68484354 -0.39314893]\n",
            " [-0.6788391  -0.38575378]\n",
            " [-0.68791974 -0.36973953]\n",
            " [-0.6869325  -0.38409078]\n",
            " [-0.68432975 -0.37923908]\n",
            " [-0.6674829  -0.4009338 ]\n",
            " [-0.6756499  -0.3861661 ]\n",
            " [-0.6885606  -0.3742732 ]\n",
            " [-0.6867473  -0.39188525]\n",
            " [-0.6828748  -0.39974403]\n",
            " [-0.6856126  -0.38110608]\n",
            " [-0.6882697  -0.3884358 ]\n",
            " [-0.68326616 -0.37212068]\n",
            " [-0.6825762  -0.38710687]\n",
            " [-0.69043815 -0.39771026]\n",
            " [-0.6830815  -0.37865302]\n",
            " [-0.67665625 -0.37585673]\n",
            " [-0.6862123  -0.3959906 ]\n",
            " [-0.6653476  -0.35215443]\n",
            " [-0.69091433 -0.38188967]\n",
            " [-0.67832834 -0.3964153 ]\n",
            " [-0.697689   -0.3861037 ]\n",
            " [-0.6743636  -0.40562642]\n",
            " [-0.6902757  -0.393895  ]\n",
            " [-0.67123514 -0.3771823 ]\n",
            " [-0.69313884 -0.39180955]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.label_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf-gan4E_2_8",
        "outputId": "c98afd59-e6a8-4e34-8a32-9f65a9bf754d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0\n",
            " 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0\n",
            " 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "YrZyflEO_5ct"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install evaluate\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O475CTkpAGJs",
        "outputId": "67307d23-fcf3-4eae-85cd-7f6ce45c10c8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting together the Trainer API code"
      ],
      "metadata": {
        "id": "EfTyRGzLWTZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapping everything togther, we can get our compute_metrics function\n",
        "# !pip install evaluate\n",
        "import evaluate\n",
        "import numpy as np\n",
        "def compute_metrics(eval_preds):\n",
        "  metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "8d8F4x80A0b8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")  # 1\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)  # 2\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"], truncation=True,\n",
        "      max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)  # 3\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer)  # 4\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")  # 5\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)  # 6\n",
        "\n",
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")  # 7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IdeT-AWDTtr",
        "outputId": "77bb7c4a-047c-45cd-9127-dce84dc8b2c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "06a24LxPEfEj",
        "outputId": "f1ca2514-ef5c-463a-c474-a5cb0b4fba0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1377/1377 03:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.684488</td>\n",
              "      <td>0.816176</td>\n",
              "      <td>0.877651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.308400</td>\n",
              "      <td>0.917826</td>\n",
              "      <td>0.835784</td>\n",
              "      <td>0.888147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.129600</td>\n",
              "      <td>0.990127</td>\n",
              "      <td>0.857843</td>\n",
              "      <td>0.900344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 460/1377 01:08 < 02:17, 6.65 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='102' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 01:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1377, training_loss=0.17081803105062734, metrics={'train_runtime': 218.6065, 'train_samples_per_second': 50.337, 'train_steps_per_second': 6.299, 'total_flos': 559439881459200.0, 'train_loss': 0.17081803105062734, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting together training code, but without Trainer API use"
      ],
      "metadata": {
        "id": "Dk5n0hMPWxUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapping everything togther, we can get our compute_metrics function\n",
        "def compute_metrics(eval_preds):\n",
        "  metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "  logits, labels = eval_preds\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "La8tAcpXR49L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")  # 1\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)  # 2\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"], truncation=True,\n",
        "      max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"idx\", \"sentence1\", \"sentence2\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets = tokenized_datasets.with_format('torch')\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer)  # 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RQ3jlWDRwUl",
        "outputId": "7ad86832-eb73-451f-8a17-7d685ca8e68d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets[\"train\"].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVkuLw8jSIwU",
        "outputId": "7e2e8179-6bed-4ffd-e4ef-88c7e7302051"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining my own dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "GvjOc7AgSTmf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check there is no mistake, we can check a batch:\n",
        "for batch in train_dataloader:\n",
        "  break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "XIS_OPYOS7sV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing done, time to load model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)  # 6/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqQmHYUnTL8F",
        "outputId": "3bf24c96-8a13-4323-a751-cbc60ce31c09"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV4J9wwITubP",
        "outputId": "e46cfd39-d12c-490a-938d-b3ee5f77eb69"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7016, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for training loop\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in train_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    lr_scheduler.step()\n",
        "    progress_bar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1182ec405fb840ad801b60a7066f7377",
            "483a70f0360e420597e074650285d68c",
            "b0bf3af1d26e450aaf723a944d6d34fc",
            "9320d63af12b40b191b6244e2d150ea6",
            "890bf9fb5c664365be97a78ffd01bc35",
            "69a9a40bb511451ba38d032daf388982",
            "0769f321a73f4f4fa492ddd7ce0ab822",
            "2626834aea964b44ab57a9943729670b",
            "3c99907ab0564200ade8ad2e9353e668",
            "9624c33b94534c978a214f91bc9b607c",
            "c910de234a6d4e59b903fc6932683927"
          ]
        },
        "id": "7fAHNQE2TxaL",
        "outputId": "ee2d5024-1d08-4ef0-8b6b-55e4e2879e46"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1377 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1182ec405fb840ad801b60a7066f7377"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    import evaluate\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj0XfbA_VSP-",
        "outputId": "d9a973b5-7dc5-4a49-812e-937bc8f80e93"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting together training code, but without Trainer API use, but this time updating training loop to work with 'accelerator'"
      ],
      "metadata": {
        "id": "-HOgNbXVXBI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(\n",
        "      example[\"sentence1\"], example[\"sentence2\"], truncation=True, max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['sentence1', 'sentence2', 'idx'])\n",
        "tokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\n",
        "tokenized_datasets.set_format('torch')\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=16, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], shuffle=True, batch_size=16, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "# To check there is no mistake, we can check a batch:\n",
        "for batch in train_dataloader:\n",
        "  break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpPfUax49sGM",
        "outputId": "ec9e5a27-0f10-4a2a-96d8-2c1447137aa3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': torch.Size([16]),\n",
              " 'input_ids': torch.Size([16, 105]),\n",
              " 'token_type_ids': torch.Size([16, 105]),\n",
              " 'attention_mask': torch.Size([16, 105])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaQuQQhp9wr4",
        "outputId": "ce0ccf8d-7109-459a-fee6-556e471e65a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing for the training loop\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "from accelerate import Accelerator\n",
        "accelerator = Accelerator()\n",
        "train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n",
        "    train_dataloader, eval_dataloader, model, optimizer\n",
        ")\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "from transformers import get_scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in train_dataloader:\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    accelerator.backward(loss)\n",
        "\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    progress_bar.update(1)"
      ],
      "metadata": {
        "id": "onvPflw4CJ4N"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import evaluate\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric.add_batch(predictions=accelerator.gather(predictions), references=accelerator.gather(batch[\"labels\"]))\n",
        "\n",
        "    metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94,
          "referenced_widgets": [
            "68364737515941329c7f28636512f74d",
            "bd562603c3674c55b0a08934a2190178",
            "89523b71b2a140bf885dfafa4d19f010",
            "dac5eb42427e46a4aa620598442e9091",
            "31e993054f1c4d2f96c7f7b2ad89ed8e",
            "00e4e3e07aaf4b8fbc8d8a73909eb546",
            "dd6f43baa94747f59773090e5c5dc9f0",
            "012dc45dcbb54ab1a008a9e2c254ee85",
            "21d047b4a2f44f6db09fc03540eed542",
            "f6cf48afd58a4574b5a6d3826cee8c66",
            "8a24db217181481ebab63fb8b4f236dc"
          ]
        },
        "id": "Mokp81a8UT6y",
        "outputId": "cb71c718-489b-46da-fb1b-3b0c47e9a29c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68364737515941329c7f28636512f74d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6862745098039216, 'f1': 0.8134110787172011}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}