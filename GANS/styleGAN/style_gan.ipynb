{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "61JnTM8LuBXd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images,\n",
        "    size per image, and images per row, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu().clamp_(0, 1)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow, padding=0)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import truncnorm # The distrubution\n",
        "def get_truncated_noise(n_samples, z_dim, truncation):\n",
        "  lower_bound = -truncation\n",
        "  upper_bound = truncation\n",
        "  # Sample from the imported distribution\n",
        "  truncated_noise = truncnorm.rvs(lower_bound, upper_bound, size=(n_samples, z_dim))\n",
        "  return torch.Tensor(truncated_noise)"
      ],
      "metadata": {
        "id": "dVO4gyhtmkES"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MappingLayers(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim, w_dim):\n",
        "        super().__init__()\n",
        "        self.mapping = nn.Sequential(\n",
        "            nn.Linear(z_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, w_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.mapping(noise)"
      ],
      "metadata": {
        "id": "4d38Bb7YoAB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InjectNoise(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(\n",
        "        torch.randn(1, channels, 1, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "    noise_shape = (image.size(0), 1, image.size(2), image.size(3))\n",
        "    noise = torch.randn(noise_shape, device=image.device)\n",
        "\n",
        "    return image + self.weight * noise"
      ],
      "metadata": {
        "id": "VtWMSSrMoCNf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaIN(nn.Module):\n",
        "  def __init__(self, channels, w_dim):\n",
        "    super().__init__()\n",
        "    self.instance_normalizer = nn.InstanceNorm2d(channels)\n",
        "    self.style_scalar = nn.Linear(w_dim, channels)\n",
        "    self.style_shifter = nn.Linear(w_dim, channels)\n",
        "\n",
        "  def forward(self, image, w):\n",
        "    normalized = self.instance_normalizer(image)  # b, c, h, w\n",
        "    # Apply styles to each channel of the image\n",
        "    scale = self.style_scalar(w)[:, :, None, None] # b, c, 1, 1\n",
        "    shift = self.style_shifter(w)[:, :, None, None] # b, c, 1, 1\n",
        "    styled_image = scale * normalized + shift\n",
        "\n",
        "    return styled_image"
      ],
      "metadata": {
        "id": "xy3yYtj0qzD7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorBlock(nn.Module):\n",
        "  def __init_(self, w_dim, in_chan, out_chan, kernel_size, starting_size, use_upsample=True):\n",
        "    super().__init__()\n",
        "    self.use_upsample = use_upsample\n",
        "    if self.use_upsample:\n",
        "      self.upsample = nn.Upsample(size=starting_size, mode=\"bilinear\", align_corners=False)\n",
        "    self.conv = nn.Conv2d(in_chan, out_chan, kernel_size, padding=1)\n",
        "    self.inject_noise = InjectNoise(out_chan)\n",
        "    self.adain = AdaIN(out_chan, w_dim)\n",
        "    self.activation = nn.LeakyReLU(0.2)\n",
        "\n",
        "  def forward(self, x, w):\n",
        "    if self.use_upsample:\n",
        "      x = self.upsample(x)\n",
        "    x = self.conv(x)\n",
        "    x = self.inject_noise(x)\n",
        "    x = self.adain(x, w)\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "nv1xxZMdwjBo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  pass"
      ],
      "metadata": {
        "id": "WflK9A5tz5V5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}